{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23381784-5daa-4970-a2ef-345919c9070b",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:center; font-size:36px; color:black; font-weight:bold\"> Default Credit Score Case</h3>\n",
    "<h3 style=\"text-align:center; font-size:26px; color:black\">Analytics</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4845427-ccf2-4441-bca8-d350f0f4cae4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee951a54-bc0b-4039-aefa-08d226f7fe2d",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to understand the business through the use of a proper regression model. We understand that more advanced models can perform better than GLMs in some cases. So, the model develped here only will be used to quantify the effect of covariates (once GLMs are fully interpretable while \"more advanced model\" not) or independent variables in the business and can be used as a baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31ac841-b2ee-41e4-948c-7aed23d5337a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a69247-9d28-4ac0-97f3-0956be0fcb5a",
   "metadata": {},
   "source": [
    "# 1. Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80ccf5e8-4808-4972-83e3-2f5758ac4b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b35aa-66b3-4bc1-b108-0f60cafb2900",
   "metadata": {},
   "source": [
    "# 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b392e61-9747-4580-a804-9f6ae1f97a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data frame: data\\processed_dataframe.csv read\n"
     ]
    }
   ],
   "source": [
    "file = os.path.join('data','processed_dataframe.csv')\n",
    "try:\n",
    "    df = pd.read_csv(file)\n",
    "    print(f' data frame: {file} read')\n",
    "    \n",
    "except:\n",
    "    print(f'error in loading dataframe, verify the path or file {file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab8bc795-0632-4892-8b33-fc636e7e1121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Default</th>\n",
       "      <th>UIS</th>\n",
       "      <th>age</th>\n",
       "      <th>NTD3059</th>\n",
       "      <th>RDW</th>\n",
       "      <th>MW</th>\n",
       "      <th>OCL</th>\n",
       "      <th>NTDGT90</th>\n",
       "      <th>NB</th>\n",
       "      <th>NTD6089</th>\n",
       "      <th>ND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Default   UIS   age  NTD3059   RDW      MW   OCL  NTDGT90   NB  NTD6089  \\\n",
       "0      1.0  0.77  45.0      2.0  0.80  9120.0  13.0      0.0  6.0      0.0   \n",
       "1      0.0  0.96  40.0      0.0  0.12  2600.0   4.0      0.0  0.0      0.0   \n",
       "2      0.0  0.66  38.0      1.0  0.09  3042.0   2.0      1.0  0.0      0.0   \n",
       "3      0.0  0.23  30.0      0.0  0.04  3300.0   5.0      0.0  0.0      0.0   \n",
       "4      0.0  0.21  74.0      0.0  0.38  3500.0   3.0      0.0  1.0      0.0   \n",
       "\n",
       "    ND  \n",
       "0  2.0  \n",
       "1  1.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.round(2).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508ef47-a069-45c5-bb19-924cb5269c4b",
   "metadata": {},
   "source": [
    "# 3. Regression Model - Binomial Model with Logistic Link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d170e95-270a-42a2-9d31-a261c361e58c",
   "metadata": {},
   "source": [
    "Once, our target (Default) data consists of two categories, default (1) and non default (0), we have some options of Generalized Linear Models (GLMs) to assess or model this kind of data, we can cite loglinear models or logistic models. By the sake of simplicity we will use a logistic regression model or the Binomial Model with logistic link function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f94a1f-5dd4-449b-aa9d-9dd09bd1c1a4",
   "metadata": {},
   "source": [
    "## 3.1. First Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cfa36b0-1926-4f73-b30e-03195f169bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.478411\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:               142966\n",
      "Model:                          Logit   Df Residuals:                   142956\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Wed, 14 Feb 2024   Pseudo R-squ.:                  0.3098\n",
      "Time:                        08:30:58   Log-Likelihood:                -68396.\n",
      "converged:                       True   LL-Null:                       -99096.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "UIS            1.7725      0.020     87.459      0.000       1.733       1.812\n",
      "age           -0.0319      0.000    -84.859      0.000      -0.033      -0.031\n",
      "RDW            0.1670      0.042      4.014      0.000       0.085       0.249\n",
      "MW         -6.444e-05   2.81e-06    -22.941      0.000   -6.99e-05   -5.89e-05\n",
      "NTD3059        0.8059      0.011     71.292      0.000       0.784       0.828\n",
      "NTD6089        1.4173      0.027     52.742      0.000       1.365       1.470\n",
      "NTDGT90        1.6129      0.024     66.715      0.000       1.566       1.660\n",
      "NB             0.0883      0.010      8.565      0.000       0.068       0.108\n",
      "ND             0.0042      0.006      0.676      0.499      -0.008       0.016\n",
      "OCL            0.0275      0.002     15.663      0.000       0.024       0.031\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Getting features and target\n",
    "X = df[['UIS','age','RDW','MW','NTD3059','NTD6089','NTDGT90','NB','ND','OCL']]\n",
    "y = np.array(df[['Default']])\n",
    "\n",
    "# Apply SMOTE to the training set\n",
    "smote = SMOTE(sampling_strategy = 'not majority', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Fiting the model\n",
    "log_model = sm.Logit(y_resampled, X_resampled)\n",
    "fit_model = log_model.fit()\n",
    "\n",
    "print(fit_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7ea622-b7f5-430f-9bcc-e320d14b02c9",
   "metadata": {},
   "source": [
    "Above is presented the result of logistic regression. As we can see in table the coefficient related to ND (Number of Dependents) have a high p-value meaning strong evidence to accept H<sub>0</sub> that is the hipothesis that the coefficient is \n",
    "null, for all the others coefficient we found strong evidence to reject H<sub>0</sub>.\n",
    "\n",
    "The statistics pseudo R-squared shows us how well the model fits to the data for GLMs, we can see that the value of statistics is low for this model 0.3098 in a scale from 0 to 1. This means that this model explains about 31% of the data variability, this can be considered not fair.\n",
    "\n",
    "Other point to note is the comparison between the log-likelihood of the full model compared to the log-likelihood of the null model (denoted by LLR-Null). As the output above give us the log-likelihood ratio test between the two models (denoted by LLR p-value), as we can see the p-value is very low, menaning that we have strong evidence to reject the hypothesis H<sub>0</sub>: \"the full model is equivalent to the null model\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fade3d88-c7e1-45dc-acce-91e74d7ae14a",
   "metadata": {},
   "source": [
    "## 3.2. Second Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d660015-b50f-42a5-8d75-89d8336df382",
   "metadata": {},
   "source": [
    "On this second iteration, we will assess the logistic regression without the variable ND, to obtain a more parsimonious model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "366e06f6-3142-4680-82ac-6a7bc79306a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.480385\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:               142966\n",
      "Model:                          Logit   Df Residuals:                   142958\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                Wed, 14 Feb 2024   Pseudo R-squ.:                  0.3070\n",
      "Time:                        08:58:40   Log-Likelihood:                -68679.\n",
      "converged:                       True   LL-Null:                       -99096.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "UIS            1.6652      0.019     85.448      0.000       1.627       1.703\n",
      "age           -0.0360      0.000   -106.352      0.000      -0.037      -0.035\n",
      "RDW            0.5374      0.038     14.025      0.000       0.462       0.613\n",
      "NTD3059        0.8001      0.011     70.896      0.000       0.778       0.822\n",
      "NTD6089        1.4160      0.027     52.681      0.000       1.363       1.469\n",
      "NTDGT90        1.6229      0.024     67.196      0.000       1.576       1.670\n",
      "NB            -0.0320      0.009     -3.563      0.000      -0.050      -0.014\n",
      "OCL            0.0135      0.002      8.167      0.000       0.010       0.017\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Getting features and target\n",
    "X_resampled = X_resampled[['UIS','age','RDW','NTD3059','NTD6089','NTDGT90','NB','OCL']]\n",
    "\n",
    "# Fiting the model\n",
    "log_model = sm.Logit(y_resampled, X_resampled)\n",
    "fit_model = log_model.fit()\n",
    "\n",
    "print(fit_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b588e3-d31d-4022-9177-302ad3b0f4ae",
   "metadata": {},
   "source": [
    "As we can see, now we have stronger evidence to reject the hypotheis H<sub>0</sub>:&beta;=0 evidenced by the low p-values associated to the coefficients. The low R-squared, evidences that the model have a low predictive power associated to it and the LLR p-value evidences that the current model is not equivalent to the null model.\n",
    "\n",
    "To compare whether the removal of ND variable has effect on the prediction of the target, we can perform the likelihood ratio test between the current model and the full model, using the following:\n",
    "\n",
    "<center> &Lambda; = -2&times;[log(Likelihood<sub>current</sub>)-log(Likelihood<sub>full</sub>)] &sim; &chi;<sup>2</sup>(1)</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c992f19-7114-4cd4-bfef-31cb9e1237c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Log-likelihood ratio test: 0.0\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Likelihood Ratio Test\n",
    "\n",
    "LLc, LLf = -68679, -68396\n",
    "LLR = -2*(LLc-LLf)\n",
    "\n",
    "pval = 1-stats.chi2.cdf(LLR, 1)\n",
    "\n",
    "print('-------------------------------------')\n",
    "print(f'Log-likelihood ratio test: {pval.round(4)}')\n",
    "print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f0b6f4-2f7c-49e1-9f0d-a0e2e7585d55",
   "metadata": {},
   "source": [
    "As we can see the p-value associated to the LLR test results in low p-value, so we have stronger evidences to reject H<sub>0</sub>: \"both the models are equivalent\".\n",
    "\n",
    "Another measure of goodness of fit is the Area Under the Receiver Operator Curve (AUC ROC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a77debf-fef6-43b1-8b95-90f831fbc4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Area Under ROC: 0.86\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Area under the ROC curve.\n",
    "AUC = roc_auc_score(y_resampled, fit_model.fittedvalues )\n",
    "\n",
    "print('-------------------------------------')\n",
    "print(f'Area Under ROC: {AUC.round(2)}')\n",
    "print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd0194e-e624-40e5-9ad3-9634c25be06b",
   "metadata": {},
   "source": [
    "As we can see the area under ROC give us a value of 0.83, meaning that the model can be considered fair, following some literatures such as Hosmer and Lemeshow.\n",
    "\n",
    "Another diagnostics for logistic regression model is the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "47bfdbd0-704e-4488-85a2-31ded1499017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57655.0</td>\n",
       "      <td>13828.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17544.0</td>\n",
       "      <td>53939.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1\n",
       "0  57655.0  13828.0\n",
       "1  17544.0  53939.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fit_model.pred_table(threshold=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0affa4fb-03f4-4b84-889b-af6930547c39",
   "metadata": {},
   "source": [
    "The confusion matrix for the parsimonious model is shown above, where the rows represent the observation and the columns represent the predicted values. We can see that both the false positive and false negative are lower than the true positive and true negatives respectively, at least 60% to 70% bellow. So, we can conclude that this model fits fairly the data and it is a good choice to quantify the effects of the covariates in analysing the defaults. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f021a60-32c3-4a53-891d-3a939f23be3a",
   "metadata": {},
   "source": [
    "# 4. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f60f1b-3b25-4809-a2eb-f08d29227900",
   "metadata": {},
   "source": [
    "* The binomial model presented can be considered a fair model to assess the default classification, evidenced by the AUC and confusion matrix.\n",
    "\n",
    "* The coefficients of the model can be interpreted as odds ratio, this analysis give us an understanding of the business, so, follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0810e436-f6ee-4f3b-9fe9-c9159e2de74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UIS</th>\n",
       "      <th>age</th>\n",
       "      <th>RDW</th>\n",
       "      <th>NTD3059</th>\n",
       "      <th>NTD6089</th>\n",
       "      <th>NTDGT90</th>\n",
       "      <th>NB</th>\n",
       "      <th>OCL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.29</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.23</td>\n",
       "      <td>4.12</td>\n",
       "      <td>5.07</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UIS   age   RDW  NTD3059  NTD6089  NTDGT90    NB   OCL\n",
       "0  5.29  0.96  1.71     2.23     4.12     5.07  0.97  1.01"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.exp(fit_model.params)).transpose().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5d4df3-95cf-4c0f-ac40-968b8ea91cbc",
   "metadata": {},
   "source": [
    "| Variable | Odds ration | Interpretation |\n",
    "| --- | --- | --- |\n",
    "| UIS | 5.29 | Each 10% of utilization of insecure credit lines relative to its limit, the odds of default rises 43% (0.43)* |\n",
    "| age | 0.96 | The odds of default decreases by 20% each 5 years of age |\n",
    "| RDW | 1.71 | Each 10% of rise in debt ratio assets represents a rise in 1.7% (0.17) of odds of default |\n",
    "| NTD3059 | 2.23 | Each time the client has been in default between 30 and 59 days, the odds of default rises by 123% (1.23) |\n",
    "| NTD6089 | 4.12 | Each time the client has been in default between 60 and 89 days, the odds of default rises by 312% (3.12) |\n",
    "| NTDGT90 | 5.07 | Each time the client has been in default above 90 days, the odds of default rises by 407% (4.07) |\n",
    "| NB | 0.97 | Each real state loan decreases by 3% (0.03) the odds of default |\n",
    "| OCL | 1.01 | Each open credit loan (number of loans) rises by 1% (0.01) the odds of default |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
