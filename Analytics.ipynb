{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23381784-5daa-4970-a2ef-345919c9070b",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:center; font-size:36px; color:black; font-weight:bold\"> Default Credit Score Case</h3>\n",
    "<h3 style=\"text-align:center; font-size:26px; color:black\">Analytics</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4845427-ccf2-4441-bca8-d350f0f4cae4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee951a54-bc0b-4039-aefa-08d226f7fe2d",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to understand the business through the use of a proper regression model. We understand that more advanced models can perform better than GLMs in some cases. So, the model develped here only will be used to quantify the effect of covariates (once GLMs are fully interpretable while \"more advanced model\" not) or independent variables in the business and can be used as a baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31ac841-b2ee-41e4-948c-7aed23d5337a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a69247-9d28-4ac0-97f3-0956be0fcb5a",
   "metadata": {},
   "source": [
    "# 1. Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80ccf5e8-4808-4972-83e3-2f5758ac4b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b35aa-66b3-4bc1-b108-0f60cafb2900",
   "metadata": {},
   "source": [
    "# 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b392e61-9747-4580-a804-9f6ae1f97a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data frame: data\\processed_dataframe.csv read\n"
     ]
    }
   ],
   "source": [
    "file = os.path.join('data','processed_dataframe.csv')\n",
    "try:\n",
    "    df = pd.read_csv(file)\n",
    "    print(f' data frame: {file} read')\n",
    "    \n",
    "except:\n",
    "    print(f'error in loading dataframe, verify the path or file {file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab8bc795-0632-4892-8b33-fc636e7e1121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Default</th>\n",
       "      <th>UIS</th>\n",
       "      <th>age</th>\n",
       "      <th>NTD3059</th>\n",
       "      <th>RDW</th>\n",
       "      <th>MW</th>\n",
       "      <th>OCL</th>\n",
       "      <th>NTDGT90</th>\n",
       "      <th>NB</th>\n",
       "      <th>NTD6089</th>\n",
       "      <th>ND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Default   UIS   age  NTD3059   RDW      MW   OCL  NTDGT90   NB  NTD6089  \\\n",
       "0      1.0  0.77  45.0      2.0  0.80  9120.0  13.0      0.0  6.0      0.0   \n",
       "1      0.0  0.96  40.0      0.0  0.12  2600.0   4.0      0.0  0.0      0.0   \n",
       "2      0.0  0.66  38.0      1.0  0.09  3042.0   2.0      1.0  0.0      0.0   \n",
       "3      0.0  0.23  30.0      0.0  0.04  3300.0   5.0      0.0  0.0      0.0   \n",
       "4      0.0  0.21  74.0      0.0  0.38  3500.0   3.0      0.0  1.0      0.0   \n",
       "\n",
       "    ND  \n",
       "0  2.0  \n",
       "1  1.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.round(2).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508ef47-a069-45c5-bb19-924cb5269c4b",
   "metadata": {},
   "source": [
    "# 3. Regression Model - Binomial Model with Logistic Link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d170e95-270a-42a2-9d31-a261c361e58c",
   "metadata": {},
   "source": [
    "Once, our target (Default) data consists of two categories, default (1) and non default (0), we have some options of Generalized Linear Models (GLMs) to assess or model this kind of data, we can cite loglinear models or logistic models. By the sake of simplicity we will use a logistic regression model or the Binomial Model with logistic link function.\n",
    "\n",
    "To achieve better results we will divide the variable MW (Monthly Wage) in units of $1k, i.e. dividing its value by 1,000.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f94a1f-5dd4-449b-aa9d-9dd09bd1c1a4",
   "metadata": {},
   "source": [
    "## 3.1. First Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4cfa36b0-1926-4f73-b30e-03195f169bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jlpsc\\AppData\\Local\\Temp/ipykernel_16304/2600278551.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['MW'] = df['MW'].copy()/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.509414\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:               142966\n",
      "Model:                          Logit   Df Residuals:                   142956\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Fri, 16 Feb 2024   Pseudo R-squ.:                  0.2651\n",
      "Time:                        23:11:55   Log-Likelihood:                -72829.\n",
      "converged:                       True   LL-Null:                       -99096.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "UIS            1.9369      0.019    100.049      0.000       1.899       1.975\n",
      "age           -0.0277      0.000    -80.375      0.000      -0.028      -0.027\n",
      "RDW            0.1009      0.040      2.532      0.011       0.023       0.179\n",
      "NTD3059        0.6425      0.010     61.486      0.000       0.622       0.663\n",
      "NTD6089        1.1007      0.026     43.155      0.000       1.051       1.151\n",
      "NTDGT90        1.2686      0.023     56.097      0.000       1.224       1.313\n",
      "NB             0.0617      0.010      6.257      0.000       0.042       0.081\n",
      "ND            -0.0264      0.006     -4.513      0.000      -0.038      -0.015\n",
      "OCL            0.0387      0.002     24.086      0.000       0.036       0.042\n",
      "MW            -0.0789      0.003    -29.173      0.000      -0.084      -0.074\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Getting features and target\n",
    "X = df[['UIS','age','RDW','NTD3059','NTD6089','NTDGT90','NB','ND','OCL']]\n",
    "X['MW'] = df['MW'].copy()/1000\n",
    "y = np.array(df[['Default']])\n",
    "\n",
    "# Apply SMOTE to the training set\n",
    "smote = SMOTE(sampling_strategy = 'not majority', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Fiting the model\n",
    "log_model = sm.Logit(y_resampled, X_resampled)\n",
    "fit_model = log_model.fit()\n",
    "\n",
    "print(fit_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7ea622-b7f5-430f-9bcc-e320d14b02c9",
   "metadata": {},
   "source": [
    "Above is presented the result of logistic regression. As we can see in table the coefficient related to ND (Number of Dependents) have a high p-value meaning strong evidence to accept H<sub>0</sub> that is the hipothesis that the coefficient is \n",
    "null, for all the others coefficient we found strong evidence to reject H<sub>0</sub>.\n",
    "\n",
    "The statistics pseudo R-squared shows us how well the model fits to the data for GLMs, we can see that the value of statistics is low for this model 0.3098 in a scale from 0 to 1. This means that this model explains about 31% of the data variability, this can be considered not fair.\n",
    "\n",
    "Other point to note is the comparison between the log-likelihood of the full model compared to the log-likelihood of the null model (denoted by LLR-Null). As the output above give us the log-likelihood ratio test between the two models (denoted by LLR p-value), as we can see the p-value is very low, menaning that we have strong evidence to reject the hypothesis H<sub>0</sub>: \"the full model is equivalent to the null model\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fade3d88-c7e1-45dc-acce-91e74d7ae14a",
   "metadata": {},
   "source": [
    "## 3.2. Second Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d660015-b50f-42a5-8d75-89d8336df382",
   "metadata": {},
   "source": [
    "On this second iteration, we will assess the logistic regression without the variable ND, to obtain a more parsimonious model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "366e06f6-3142-4680-82ac-6a7bc79306a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.509486\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:               142966\n",
      "Model:                          Logit   Df Residuals:                   142957\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Fri, 16 Feb 2024   Pseudo R-squ.:                  0.2650\n",
      "Time:                        23:12:36   Log-Likelihood:                -72839.\n",
      "converged:                       True   LL-Null:                       -99096.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "UIS            1.9263      0.019    100.267      0.000       1.889       1.964\n",
      "age           -0.0276      0.000    -80.273      0.000      -0.028      -0.027\n",
      "RDW            0.0780      0.040      1.974      0.048       0.001       0.155\n",
      "NTD3059        0.6408      0.010     61.384      0.000       0.620       0.661\n",
      "NTD6089        1.0994      0.026     43.088      0.000       1.049       1.149\n",
      "NTDGT90        1.2666      0.023     56.036      0.000       1.222       1.311\n",
      "NB             0.0631      0.010      6.409      0.000       0.044       0.082\n",
      "OCL            0.0389      0.002     24.229      0.000       0.036       0.042\n",
      "MW            -0.0822      0.003    -31.451      0.000      -0.087      -0.077\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Getting features and target\n",
    "X_resampled = X_resampled[['UIS','age','RDW','NTD3059','NTD6089','NTDGT90','NB','OCL','MW']]\n",
    "\n",
    "# Fiting the model\n",
    "log_model = sm.Logit(y_resampled, X_resampled)\n",
    "fit_model = log_model.fit()\n",
    "\n",
    "print(fit_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b588e3-d31d-4022-9177-302ad3b0f4ae",
   "metadata": {},
   "source": [
    "As we can see, now we have stronger evidence to reject the hypotheis H<sub>0</sub>:&beta;=0 evidenced by the low p-values associated to the coefficients. The low R-squared, evidences that the model have a low predictive power associated to it and the LLR p-value evidences that the current model is not equivalent to the null model.\n",
    "\n",
    "To compare whether the removal of ND variable has effect on the prediction of the target, we can perform the likelihood ratio test between the current model and the full model, using the following:\n",
    "\n",
    "<center> &Lambda; = -2&times;[log(Likelihood<sub>current</sub>)-log(Likelihood<sub>full</sub>)] &sim; &chi;<sup>2</sup>(&nu;)</center>\n",
    "\n",
    "\n",
    "where &nu; is the degrees of freedom of &chi;<sup>2</sup> distribution given by the subtraction between the number of features of the full model to the current model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7c992f19-7114-4cd4-bfef-31cb9e1237c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Log-likelihood ratio test: 0.0000\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Likelihood Ratio Test\n",
    "\n",
    "LLc, LLf = -72839, -72829\n",
    "LLR = -2*(LLc-LLf)\n",
    "\n",
    "pval = 1-stats.chi2.cdf(LLR, 1)\n",
    "\n",
    "print('-------------------------------------')\n",
    "print(f'Log-likelihood ratio test: {pval:.4f}')\n",
    "print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f0b6f4-2f7c-49e1-9f0d-a0e2e7585d55",
   "metadata": {},
   "source": [
    "As we can see the p-value associated to the LLR test results in low p-value, so we have stronger evidences to reject H<sub>0</sub>: \"both the models are equivalent\".\n",
    "\n",
    "Another measure of goodness of fit is the Area Under the Curve of Receiver Operator Characteristic (AUC ROC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a77debf-fef6-43b1-8b95-90f831fbc4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Area Under ROC: 0.84\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Area under the ROC curve.\n",
    "AUC = roc_auc_score(y_resampled, fit_model.fittedvalues )\n",
    "\n",
    "print('-------------------------------------')\n",
    "print(f'Area Under ROC: {AUC.round(2)}')\n",
    "print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd0194e-e624-40e5-9ad3-9634c25be06b",
   "metadata": {},
   "source": [
    "As we can see the area under ROC give us a value of 0.83, meaning that the model can be considered fair, following some literatures such as Hosmer and Lemeshow.\n",
    "\n",
    "Another diagnostics for logistic regression model is the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47bfdbd0-704e-4488-85a2-31ded1499017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55609.0</td>\n",
       "      <td>15874.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19025.0</td>\n",
       "      <td>52458.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1\n",
       "0  55609.0  15874.0\n",
       "1  19025.0  52458.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fit_model.pred_table(threshold=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0affa4fb-03f4-4b84-889b-af6930547c39",
   "metadata": {},
   "source": [
    "The confusion matrix for the parsimonious model is shown above, where the rows represent the observation and the columns represent the predicted values. We can see that both the false positive and false negative are lower than the true positive and true negatives respectively, at least 60% to 70% bellow. So, we can conclude that this model fits fairly the data and it is a good choice to quantify the effects of the covariates in analysing the defaults. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f021a60-32c3-4a53-891d-3a939f23be3a",
   "metadata": {},
   "source": [
    "# 4. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f60f1b-3b25-4809-a2eb-f08d29227900",
   "metadata": {},
   "source": [
    "* The binomial model presented can be considered a fair model to assess the default classification, evidenced by the AUC and confusion matrix.\n",
    "\n",
    "* The coefficients of the model can be interpreted as odds ratio, this analysis give us an understanding of the business, so, follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0810e436-f6ee-4f3b-9fe9-c9159e2de74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UIS</th>\n",
       "      <th>age</th>\n",
       "      <th>RDW</th>\n",
       "      <th>NTD3059</th>\n",
       "      <th>NTD6089</th>\n",
       "      <th>NTDGT90</th>\n",
       "      <th>NB</th>\n",
       "      <th>OCL</th>\n",
       "      <th>MW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.864395</td>\n",
       "      <td>0.972774</td>\n",
       "      <td>1.081138</td>\n",
       "      <td>1.897967</td>\n",
       "      <td>3.002398</td>\n",
       "      <td>3.54874</td>\n",
       "      <td>1.065176</td>\n",
       "      <td>1.039683</td>\n",
       "      <td>0.921128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        UIS       age       RDW   NTD3059   NTD6089  NTDGT90        NB  \\\n",
       "0  6.864395  0.972774  1.081138  1.897967  3.002398  3.54874  1.065176   \n",
       "\n",
       "        OCL        MW  \n",
       "0  1.039683  0.921128  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.exp(fit_model.params)).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5d4df3-95cf-4c0f-ac40-968b8ea91cbc",
   "metadata": {},
   "source": [
    "| Variable | Odds ration | Interpretation |\n",
    "| --- | --- | --- |\n",
    "| UIS | 6.86 | Each 10% of utilization of insecure credit lines relative to its limit, the odds of default rises 53% (0.53)* |\n",
    "| age | 0.97 | The odds of default decreases by 15% (-0.03&times;5) each 5 years of age |\n",
    "| RDW | 1.08 | Each 1% of rise in debt ratio assets represents a rise in 8% (0.08) of odds of default |\n",
    "| NTD3059 | 1.89 | The odds of default rises by 89% (0.89), each time the client had been in default between 30 and 59 days |\n",
    "| NTD6089 | 3.00 | The odds of default rises by 200% (2.00), each time the client had been in default between 60 and 89 days |\n",
    "| NTDGT90 | 3.55 | The odds of default rises by 255% (2.55), each time the client had been in default above 90 days |\n",
    "| NB | 1.07 | Each real state loan increases by 7% (0.07) the odds of default |\n",
    "| OCL | 1.04 | Each open credit line (number of loans) rises by 4% (0.04) the odds of default |\n",
    "| MW | 0.92 | Each $1000 in monthly earnings decrease the oddos of default by 8% (-0.08) |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
